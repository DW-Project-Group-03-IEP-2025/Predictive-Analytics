{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c42c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# THIS SCRIPT LOADS DATA FROM MSSQL, FITS A PROPHET MODEL,\n",
    "# PERFORMS ADAPTIVE CROSS-VALIDATION, FORECASTS FUTURE VALUES,\n",
    "# AND PUSHES THE RESULTS BACK TO MSSQL.\n",
    "# IT ALSO PLOTS THE FORECAST WITH TOTAL FORECASTED VALUE.\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2495ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# CONFIGURATION\n",
    "# ================================\n",
    "CONFIG = {\n",
    "    # --- MSSQL PULL ---\n",
    "    'sql_query': \"\"\"\n",
    "        SELECT fulldate AS order_date, salesamount AS NetSales\n",
    "FROM main.dbo._Gift_from_Carpenters\n",
    "WHERE NetSales IS NOT NULL\n",
    "    \"\"\",\n",
    "    'server': '100.99.225.51',\n",
    "    'database': 'main',\n",
    "    'username': 'SA',\n",
    "    'password': 'a31536000',\n",
    "    'driver': '{ODBC Driver 17 for SQL Server}',\n",
    "    'encrypt': 'yes',\n",
    "    'trust_server_certificate': 'yes',\n",
    "\n",
    "    # --- TIMEOUTS (Critical for bulk ops) ---\n",
    "    'connection_timeout': 120,   # 2 minutes\n",
    "    'query_timeout': 300,        # 5 minutes\n",
    "\n",
    "    # --- FORECAST SETTINGS ---\n",
    "    'date_column': None,\n",
    "    'value_column': None,\n",
    "    'date_format': '%d/%m/%Y',\n",
    "    'aggregation_freq': 'D',           # D, W, M\n",
    "    'forecast_periods': 365,\n",
    "\n",
    "    # --- CROSS-VALIDATION ---\n",
    "    'cv_initial': '3D',\n",
    "    'cv_period': '1D',\n",
    "    'cv_horizon': '4D',\n",
    "\n",
    "    # --- PUSH ---\n",
    "    'target_table': 'sales_forecasted_data',\n",
    "\n",
    "    # --- PLOT ---\n",
    "    'plot_title': 'Sales Forecast (_Gift_from_Carpenters)',\n",
    "    'plot_xlabel': 'Date',\n",
    "    'plot_ylabel': 'Sales (USD)'\n",
    "}\n",
    "\n",
    "# Frequency mapping\n",
    "FREQ_MAP_RESAMPLE = {'D': 'D', 'W': 'W-MON', 'M': 'MS'}\n",
    "FREQ_MAP_PROPHET = {'D': 'D', 'W': 'W', 'M': 'MS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df2fe7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. LOAD FROM MSSQL\n",
    "# ================================\n",
    "def load_data(config):\n",
    "    conn_str = (\n",
    "        f\"DRIVER={config['driver']};\"\n",
    "        f\"SERVER={config['server']};\"\n",
    "        f\"DATABASE={config['database']};\"\n",
    "        f\"UID={config['username']};\"\n",
    "        f\"PWD={config['password']};\"\n",
    "        f\"Encrypt={config['encrypt']};\"\n",
    "        f\"TrustServerCertificate={config['trust_server_certificate']};\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Connecting to MSSQL...\")\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        df = pd.read_sql(config['sql_query'], conn)\n",
    "        conn.close()\n",
    "        print(f\"Loaded {len(df):,} rows from DB\")\n",
    "\n",
    "        # Auto-detect\n",
    "        date_col = config['date_column'] or 'order_date'\n",
    "        value_col = config['value_column'] or 'NetSales'\n",
    "\n",
    "        df[date_col] = pd.to_datetime(df[date_col], format=config['date_format'], errors='coerce')\n",
    "        df[value_col] = pd.to_numeric(df[value_col], errors='coerce')\n",
    "        df = df.dropna(subset=[date_col, value_col])\n",
    "\n",
    "        print(f\"Cleaned data: {len(df):,} rows\")\n",
    "        return df, date_col, value_col\n",
    "    except Exception as e:\n",
    "        print(f\"DB Load Failed: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dfc66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2. AGGREGATE\n",
    "# ================================\n",
    "def aggregate_data(df, date_col, value_col, freq):\n",
    "    try:\n",
    "        agg_df = df.groupby(date_col)[value_col].sum().reset_index()\n",
    "        agg_df.columns = ['ds', 'y']\n",
    "        if freq != 'D':\n",
    "            agg_df.set_index('ds', inplace=True)\n",
    "            resample_freq = FREQ_MAP_RESAMPLE.get(freq, 'D')\n",
    "            agg_df = agg_df.resample(resample_freq).sum().reset_index()\n",
    "            agg_df['y'] = agg_df['y'].fillna(0)\n",
    "        return agg_df\n",
    "    except Exception as e:\n",
    "        print(f\"Aggregation error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67e29d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 3. FIT MODEL\n",
    "# ================================\n",
    "def fit_prophet_model(df):\n",
    "    try:\n",
    "        model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True)\n",
    "        model.fit(df)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Model fit error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c1abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 4. FORECAST\n",
    "# ================================\n",
    "def make_forecast(model, periods, freq):\n",
    "    try:\n",
    "        prophet_freq = FREQ_MAP_PROPHET.get(freq, 'D')\n",
    "        future = model.make_future_dataframe(periods=periods, freq=prophet_freq)\n",
    "        forecast = model.predict(future)\n",
    "        return forecast\n",
    "    except Exception as e:\n",
    "        print(f\"Forecast error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9607c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 5. CROSS-VALIDATION (ADAPTIVE)\n",
    "# ================================\n",
    "def run_cross_validation(model, config, agg_df):\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CROSS-VALIDATION\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        data_span = (agg_df['ds'].max() - agg_df['ds'].min()).days\n",
    "        horizon_days = int(config['cv_horizon'].replace('D', ''))\n",
    "        initial_days = int(config['cv_initial'].replace('D', ''))\n",
    "\n",
    "        min_needed = initial_days + horizon_days\n",
    "        if data_span < min_needed:\n",
    "            scale = data_span / min_needed * 0.8\n",
    "            initial_days = max(180, int(initial_days * scale))\n",
    "            horizon_days = max(30, int(horizon_days * scale))\n",
    "            print(f\"Data too short â†’ Adjusted: initial={initial_days}D, horizon={horizon_days}D\")\n",
    "\n",
    "        df_cv = cross_validation(\n",
    "            model,\n",
    "            initial=f\"{initial_days}D\",\n",
    "            period=config['cv_period'],\n",
    "            horizon=f\"{horizon_days}D\",\n",
    "            parallel=\"processes\"\n",
    "        )\n",
    "        df_perf = performance_metrics(df_cv)\n",
    "\n",
    "        print(f\"CV Success: {len(df_cv)} predictions\")\n",
    "        print(f\"MAE: {df_perf['mae'].mean():,.2f} | MAPE: {df_perf['mape'].mean():.2%}\")\n",
    "        return df_cv, df_perf\n",
    "    except Exception as e:\n",
    "        print(f\"CV Failed: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8ba58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================\n",
    "# 6. PUSH TO DB\n",
    "# ================================\n",
    "def push_forecast_to_db(future_forecast, config):\n",
    "    conn_str = (\n",
    "        f\"DRIVER={config['driver']};\"\n",
    "        f\"SERVER={config['server']};\"\n",
    "        f\"DATABASE={config['database']};\"\n",
    "        f\"UID={config['username']};\"\n",
    "        f\"PWD={config['password']};\"\n",
    "        f\"Encrypt={config['encrypt']};\"\n",
    "        f\"TrustServerCertificate={config['trust_server_certificate']};\"\n",
    "    )\n",
    "    try:\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        table = config['target_table']\n",
    "        cursor.execute(f\"\"\"\n",
    "            IF NOT EXISTS (SELECT * FROM sys.tables WHERE name = '{table}')\n",
    "            CREATE TABLE {table} (\n",
    "                forecast_date DATE PRIMARY KEY,\n",
    "                yhat FLOAT,\n",
    "                yhat_lower FLOAT,\n",
    "                yhat_upper FLOAT,\n",
    "                created_at DATETIME DEFAULT GETDATE()\n",
    "            )\n",
    "        \"\"\")\n",
    "        cursor.execute(f\"TRUNCATE TABLE {table}\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Push via SQLAlchemy (fast bulk)\n",
    "        engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={conn_str.replace(';', '%3B')}\")\n",
    "        future_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].rename(columns={'ds': 'forecast_date'}).to_sql(\n",
    "            table, engine, if_exists='append', index=False, method='multi'\n",
    "        )\n",
    "        conn.close()\n",
    "        print(f\"Pushed {len(future_forecast)} rows to `{table}`\")\n",
    "    except Exception as e:\n",
    "        print(f\"Push failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "618bd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 7. PLOT\n",
    "# ================================\n",
    "def plot_forecast(model, forecast, agg_df, title, xlabel, ylabel):\n",
    "    try:\n",
    "        fig = model.plot(forecast)\n",
    "        plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "        model.plot_components(forecast)\n",
    "        plt.show()\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        print(f\"Plot error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "965d24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 8. TRAINING & VALIDATION METRICS\n",
    "# ================================\n",
    "def print_metrics(model, forecast, agg_df, cv_results):\n",
    "    try:\n",
    "        # --- TRAINING METRICS ---\n",
    "        train_pred = forecast[forecast['ds'].isin(agg_df['ds'])].copy()\n",
    "        train_actual = agg_df.set_index('ds')['y']\n",
    "        train_pred = train_pred.set_index('ds')['yhat']\n",
    "        train_pred = train_pred.reindex(train_actual.index).fillna(0)\n",
    "\n",
    "        mae_train = mean_absolute_error(train_actual, train_pred)\n",
    "        mape_train = np.mean(np.abs((train_actual - train_pred) / train_actual.replace(0, np.nan))) * 100\n",
    "        rmse_train = np.sqrt(mean_squared_error(train_actual, train_pred))\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TRAINING METRICS (In-Sample Fit)\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"MAE : {mae_train:,.2f}\")\n",
    "        print(f\"MAPE: {mape_train:,.2f}%\")\n",
    "        print(f\"RMSE: {rmse_train:,.2f}\")\n",
    "\n",
    "        # --- VALIDATION METRICS (from CV) ---\n",
    "        if cv_results is not None:\n",
    "            df_perf = performance_metrics(cv_results)\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"VALIDATION METRICS (Cross-Validation)\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"MAE : {df_perf['mae'].mean():,.2f}\")\n",
    "            print(f\"MAPE: {df_perf['mape'].mean():,.2f}%\")\n",
    "            print(f\"RMSE: {df_perf['rmse'].mean():,.2f}\")\n",
    "        else:\n",
    "            print(\"\\nValidation metrics skipped (CV failed)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Metrics error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5823ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    df, date_col, value_col = load_data(config)\n",
    "    if df is None: return\n",
    "    agg_df = aggregate_data(df, date_col, value_col, config['aggregation_freq'])\n",
    "    if agg_df is None: return\n",
    "    model = fit_prophet_model(agg_df)\n",
    "    if model is None: return\n",
    "    forecast = make_forecast(model, config['forecast_periods'], config['aggregation_freq'])\n",
    "    if forecast is None: return\n",
    "\n",
    "    # CV\n",
    "    cv_results, _ = run_cross_validation(model, config, agg_df)\n",
    "\n",
    "    # METRICS\n",
    "    print_metrics(model, forecast, agg_df, cv_results)\n",
    "\n",
    "    # Total Forecast\n",
    "    future = forecast[~forecast['ds'].isin(agg_df['ds'])].copy()\n",
    "    total = future['yhat'].sum()\n",
    "    print(f\"\\nTOTAL FORECAST ({config['forecast_periods']} days): ${total:,.2f}\")\n",
    "\n",
    "    # Push\n",
    "    push_forecast_to_db(future, config)\n",
    "\n",
    "    # Plot\n",
    "    fig = plot_forecast(model, forecast, agg_df, config['plot_title'], config['plot_xlabel'], config['plot_ylabel'])\n",
    "    if fig:\n",
    "        ax = fig.axes[0]\n",
    "        ax.axhline(total, color='green', linestyle='--', label=f'Total: ${total:,.0f}')\n",
    "        ax.text(forecast['ds'].max(), total, f' ${total:,.0f}', color='green', fontweight='bold')\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "459686c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to MSSQL...\n",
      "DB Load Failed: ('28000', '[28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Login failed for user \\'sa\\'. (18456) (SQLDriverConnect); [28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot open database \"main\" requested by the login. The login failed. (4060); [28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Login failed for user \\'sa\\'. (18456); [28000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot open database \"main\" requested by the login. The login failed. (4060)')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6546563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
